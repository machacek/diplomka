#!/bin/bash
# eman seed for joshua grammar extraction
# Note that different grammars are extracted for the development and for the test set.
# Copyright Â© 2012 Dan Zeman <zeman@ufal.mff.cuni.cz>
# License: GNU GPL

function die() { echo "$@" >&2; exit 1; }
set -o pipefail  # safer pipes

# Ensure all the required variables are set (or provide the default)
[ -z "$STATMT" ] && die "\$STATMT must contain the full path to the root of your working copy of the StatMT repository (one level above playground)"
eman \
  defvar BINARIZESTEP type=reqstep help='where is the binarized parallel corpus and word alignment' \
  defvar JOSHUASTEP type=reqstep inherit=BINARIZESTEP help='where is compiled Joshua' \
  defvar JOSHUA inherit=JOSHUASTEP help='where is compiled Joshua' \
  defvar DATASTEP type=reqstep inherit=BINARIZESTEP help='where are dev.$SRC.gz and test.$SRC.gz' \
  defvar SRC inherit=BINARIZESTEP help='source language code' \
  defvar TGT inherit=BINARIZESTEP help='target language code' \
  defvar FOR default='dev' help='what are we going to translate (dev|test)' \
|| exit 1

# Set local bash variables
eval `eman bash-loadvars`
[ "$FOR" == "dev" ] || [ "$FOR" == "test" ] || die "FOR=$FOR, must be dev or test"
FORFILE=$FOR.$SRC.gz

eman add-tag $SRC-$TGT .

# Stop here if we are just initing ourselves
[ -z "$INIT_ONLY" ] || exit 0

# convert the dependencies to absolute paths
DATASTEPDIR=`eman path $DATASTEP`
BINARIZESTEPDIR=`eman path $BINARIZESTEP`

# Run checks in the preparation phase
# The input files may not yet exist if the previous steps are still running so we must check their existence inside eman.command.

# Emit the main script to be used in the running phase
cat > eman.command << KONEC
#!/bin/bash
echo "=============================="
echo "== Started:   "\`date '+%Y%m%d-%H%M'\`
echo "== Hostname:  "\`hostname\`
echo "== Directory: "\`pwd\`
echo "=============================="
mydir=\$(pwd)
set -o pipefail
function die() { echo "\$@" >&2 ; eman fail \$mydir ; exit 1 ; }
renice 10 \$\$
ulimit -c 1 # core files limited to 1 byte

# Check that the input files exist.
for i in source.corpus target.corpus common.vocab source.suffixes target.suffixes alignment.grids lexicon.counts lexprobs.txt frequentPhrases ; do
  [ -f $BINARIZESTEPDIR/\$i ] || die "File $BINARIZESTEPDIR/\$i not found"
done
[ -f $DATASTEPDIR/$FORFILE ] || die "File $DATASTEPDIR/$FORFILE not found"
# The source text for which the grammar will be extracted must be gunzipped first.
gunzip -c $DATASTEPDIR/$FORFILE > src.txt || die "Cannot gunzip the source text"
# Now extract the grammar for the given test set from the binarized corpus.
# Note that the following Perl script submits its own child jobs to the cluster.
# JOSHUA may exist when generating this script but it also must exist and be exported when parextract.pl is invoked!
# JOSHUA_VERSION should be inherited from the $JOSHUASTEP but we now support only 1.3 anyway.
export JOSHUA=$JOSHUA
export JOSHUA_VERSION=1.3
$STATMT/joshua-scripts/parextract.pl $BINARIZESTEPDIR src.txt grammar.raw `pwd`/parextract \\
|| die "Parallelized grammar extraction failed"
# Remove the temporary gunzipped file.
rm -f src.txt || die "Cannot remove the temporary src.txt"
# Sort the grammar, remove duplicate rules and gzip it.
sort -u grammar.raw > grammar || die "Failed to uniquely sort the grammar rules"
rm -f grammar.raw || die "Failed to remove the raw grammar"
rm -f grammar.gz || die "Failed to remove grammar.gz"
gzip grammar || die "Failed to gzip the grammar"

# Standard command footer
echo Done.
eman succeed \$mydir
echo "=============================="
echo "== Ended:     "\`date '+%Y%m%d-%H%M'\`
echo "== Hostname:  "\`hostname\`
echo "== Directory: "\`pwd\`
echo "=============================="
KONEC
